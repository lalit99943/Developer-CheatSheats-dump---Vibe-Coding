import { CheatSheet } from '../../types';

export const springAiCheatSheets: CheatSheet[] = [
  {
    id: 'spring-ai-1',
    category: 'Spring AI',
    subCategory: 'xml',
    title: 'OpenAI Starter Dependency',
    snippet: `<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
</dependency>`,
    description: 'The easiest way to get started with Spring AI and OpenAI. This starter includes the AI core, OpenAI client, and auto-configuration.',
    tags: ['spring ai', 'maven', 'pom', 'dependency', 'openai', 'starter'],
  },
  {
    id: 'spring-ai-2',
    category: 'Spring AI',
    subCategory: 'properties',
    title: 'Configure OpenAI API Key',
    snippet: '# application.properties\nspring.ai.openai.api-key=YOUR_OPENAI_API_KEY\nspring.ai.openai.chat.options.model=gpt-4o',
    description: 'Configure your OpenAI API key and optionally specify the chat model to use in your application properties file.',
    tags: ['spring ai', 'properties', 'configuration', 'openai', 'api-key'],
  },
  {
    id: 'spring-ai-3',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'Basic Chat Request',
    snippet: `@RestController
public class ChatController {

    private final ChatClient chatClient;

    @Autowired
    public ChatController(ChatClient chatClient) {
        this.chatClient = chatClient;
    }

    @GetMapping("/ai/simple")
    public String simpleChat() {
        return chatClient.call("Tell me a joke");
    }
}`,
    description: 'The ChatClient is the central interface for interacting with LLMs. Autowire it and use the .call() method for a simple request-response interaction.',
    tags: ['spring ai', 'chatclient', 'llm', 'ai', 'java', 'openai'],
  },
  {
    id: 'spring-ai-4',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'Using Prompt Templates',
    snippet: `@GetMapping("/ai/prompt")
public String promptWithRole(@RequestParam String subject) {
    PromptTemplate promptTemplate = new PromptTemplate("Tell me a joke about {subject}.");
    Prompt prompt = promptTemplate.create(Map.of("subject", subject));
    return chatClient.call(prompt).getResult().getOutput().getContent();
}`,
    description: 'Prompt templates allow you to create dynamic prompts with placeholders. Use a map to fill in the variables before sending the prompt to the ChatClient.',
    tags: ['spring ai', 'prompt', 'template', 'dynamic', 'java'],
  },
  {
    id: 'spring-ai-5',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'Streaming Chat Responses',
    snippet: `@GetMapping("/ai/stream")
public Flux<String> streamChat() {
    return chatClient.stream("Tell me a long story about a robot.")
                     .map(ChatResponse::getResult)
                     .map(Result::getOutput)
                     .map(AssistantMessage::getContent);
}`,
    description: 'For real-time, token-by-token responses, use the .stream() method. It returns a Project Reactor Flux that emits content as it is generated by the model.',
    tags: ['spring ai', 'stream', 'flux', 'reactive', 'chatclient', 'java'],
  },
  {
    id: 'spring-ai-6',
    category: 'Spring AI',
    subCategory: 'xml',
    title: 'Ollama Starter Dependency',
    snippet: `<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
</dependency>`,
    description: 'Use this starter to connect your Spring AI application to a local LLM running via Ollama. This is great for local development and testing.',
    tags: ['spring ai', 'maven', 'pom', 'dependency', 'ollama', 'local-llm'],
  },
  {
    id: 'spring-ai-7',
    category: 'Spring AI',
    subCategory: 'properties',
    title: 'Configure Local Ollama Model',
    snippet: '# application.properties\nspring.ai.ollama.base-url=http://localhost:11434\n\nspring.ai.ollama.chat.options.model=llama3',
    description: 'After adding the dependency, configure the base URL for your Ollama instance and specify which local model you want to use.',
    tags: ['spring ai', 'properties', 'configuration', 'ollama', 'local-llm'],
  },
  {
    id: 'spring-ai-8',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'RAG: Loading and Vectorizing Documents',
    snippet: `@Bean
public ApplicationRunner ragRunner(VectorStore vectorStore, ResourceLoader resourceLoader) {
    return args -> {
        // Load documents from a resource
        Resource pdfResource = resourceLoader.getResource("classpath:my-document.pdf");
        TikaDocumentReader tikaReader = new TikaDocumentReader(pdfResource);
        List<Document> documents = tikaReader.get();

        // Add documents to the VectorStore (embeddings are created automatically)
        vectorStore.add(documents);
    };
}`,
    description: 'For Retrieval-Augmented Generation (RAG), first load your external knowledge into Document objects. Then, add them to a VectorStore, which will automatically create vector embeddings.',
    tags: ['spring ai', 'rag', 'vectorstore', 'documents', 'embedding', 'retrieval'],
  },
  {
    id: 'spring-ai-9',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'RAG: Augmenting a Prompt',
    snippet: `public String ragQuery(String userQuery) {
    // 1. Retrieve relevant documents from the VectorStore
    List<Document> similarDocuments = vectorStore.similaritySearch(userQuery);
    String context = similarDocuments.stream()
            .map(Document::getContent)
            .collect(Collectors.joining(System.lineSeparator()));

    // 2. Create a prompt with the retrieved context
    String template = """
            Answer the user's question based on the following information:
            {context}
            
            Question: {question}
            """;
    PromptTemplate promptTemplate = new PromptTemplate(template);
    Prompt prompt = promptTemplate.create(Map.of(
        "context", context, 
        "question", userQuery
    ));

    // 3. Call the LLM with the augmented prompt
    return chatClient.call(prompt).getResult().getOutput().getContent();
}`,
    description: 'The core of RAG: find documents semantically similar to the user\'s query, inject their content into a prompt as context, and then ask the LLM to answer based on that context.',
    tags: ['spring ai', 'rag', 'prompt', 'context', 'vectorstore', 'retrieval'],
  },
  {
    id: 'spring-ai-10',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'Function Calling',
    snippet: `// In your ChatController, referencing a bean that defines the function
ChatResponse response = chatClient.call(new Prompt(
    "What's the weather like in San Francisco?",
    AiOptions.builder().withFunction("weatherFunction").build()
));

// Function definition in another bean
@Bean
@Description("Get the weather in a location")
public Function<WeatherRequest, WeatherResponse> weatherFunction() {
    return (request) -> new WeatherResponse("The weather in " + request.location() + " is sunny.");
}
`,
    description: 'Enable the LLM to call your application\'s Java functions. Define a Function bean with an @Description annotation and reference its name in the ChatClient call options. Spring AI handles the mapping.',
    tags: ['spring ai', 'function calling', 'tools', 'llm', 'api'],
  },
  {
    id: 'spring-ai-11',
    category: 'Spring AI',
    subCategory: 'java',
    title: 'Image Generation',
    snippet: `@Autowired
private ImageClient imageClient;

public String generateImage() {
    ImagePrompt imagePrompt = new ImagePrompt("A photorealistic cat astronaut on the moon.");
    ImageResponse response = imageClient.call(imagePrompt);
    String imageUrl = response.getResult().getOutput().getUrl();
    return imageUrl;
}`,
    description: 'Use the ImageClient interface to generate images from a text prompt. The client must be backed by a model that supports image generation (e.g., DALL-E 3 with OpenAI).',
    tags: ['spring ai', 'image generation', 'imageclient', 'dalle', 'openai'],
  },
];
